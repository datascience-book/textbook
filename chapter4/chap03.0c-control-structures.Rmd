--- 
title: "Data Science + Public Policy"
author: "Jeffrey Chen"
date: '`r Sys.Date()`'
output:
  html_document: default
  latex_engine: xelatex
  pdf_document: null
description: Manipulation - Control Structures - Etiquette
documentclass: book
link-citations: yes
bibliography:
- book.bib
- packages.bib
site: bookdown::bookdown_site
biblio-style: apalikex
---



##Control Structures
Much of data science requires developing specialized code to handle the eccentricities of a dataset. Re-running blocks of code is required, often times on multiple data samples and subpopulations. It's simply not scalable to manually change variables and assumptions of the code everytime. 

Variables are typically treated differently based on their quality and characteristics. In order to accomplish analytical and programming tasks, control structures are used to determine how a program will treat a given variable given conditions and parameters. In this section, we will cover two commonly used control structures: if...else statements and for loops.

###If and If...Else Statement
If statements evaluate a logical statement, then execute a script based on whether the evaluated statement is true or false. If the statement is `TRUE`, then the code block is executed.

```{r}
  budget <- 450
  if(budget > 400){
    #If statement true, run script goes here
    print("You're over budget. Cut back.")
  }
```

In cases where there are two or more choices, if...else statements would be appropriate. In addition to the `if()` statement, an `else` statement is included to handle cases where the logical statement is `FALSE`.


```{r, eval=FALSE}
  budget <- 399  
  if(budget >= 400){
    #If statement true, run script goes here
    print("You're over budget. Cut back.")
  } else {
    #else, run script goes here
    print("You're under budget, but watch it.")
  }
```

The complexity of these statements can be as simple as `if(x > 10){ print("Hello")}` more complex trees:

```{r}
  age <- 23
    
  if(age <= 12){
      print("kid")
    } else if(age >12 && age <20) {
      print("teenager")
    } else if(age >=20 && age <65) {
      print("adult")
    } else{
      print("senior")
    }
```


###For-loops
Loops can be used to run the a given statement of code multiple times for a specified number of times or a list of index value. This is a functionality that is available in most programming languages, but the programming syntax will be different. Conceptually, for loops can be likened to an assembly line in a car factory. In order to build a car, a series of well-defined, well-timed processes need to coordinated in a serial fashion. To build 500 cars, the process needs to be executed 500 times. For-loops are essentially the same: Given a well-defined, self-contained process, a process can be be iterativelyapplied to address repetive tasks.

Let's take the following example. The code block essentially says "print values for the range of 1 through 5", where `i` is an *index value*. When executing the statement, R will push the first value in the sequence of 1:5 into the index (in this case, it's the number 1), then the code block in between the `{}` (curly brackets) will be executed, treating `i` as if it's the number 1. Upon executing the code without error, R will advance to the next value in the sequence and repeat the process until all values in the sequence have been completed.

```{r}
  for(i in 1:5){
    print(paste0("Car #", i))
  }
```

We can do the same for a vector or list of values. In the example below, the vector `news` contains six terms. Using a for-loop, we can print out each word in the vector. 

```{r}
  news <- c("The","Dow","Is","Up","By","400pts")
  for(i in news){
    print(i)
  }
```

For-loops has a few qualities that users should be aware. First, what happens within the for-loop is written to the R environment as _global variables_. That means that any object (e.g. calculations, models) that is created in the loop will be accessible in the programming enviromment even after the loop ends. This may be a good or bad, depending on the use case: Good if one wants to keep copies of the intermediate results of a loop iteration, but bad if the user is not careful to take note of the potential floor of extraneous objects that may effect downstream calculations.  Second, one of the most common mistakes when using loops is failing to record the result of the loop. There are functions in R that are designed to log and package results from loops, but in plain vanilla loops, this is not the case. 

__A common paradigm__ with for-loops is to iteratively execute repetitive tasks. For example, if a calculation needed to be applied to each of one million files and the results need to be logged, then for-loops are a good option. Typically, the paradigm proceeds as follows:

1. Create placeholder object (e.g. a vector, matrix, or data frame);
2. Initialize loop; and
3. Add outputs to placeholder at the end of each loop iteration. 

This may be applied in a broad variety of cases such as processes each data set in a repository of many large data sets, calculating complex statistics for various strata and subsets within the data, among others. Best practices with loops start with initializing new placeholder objects to full length before the loop rather than increasing the object size within the loop^[https://www.r-project.org/doc/Rnews/Rnews_2008-1.pdf]. In R, this is particularly important issue for efficient data processing. 

In the example below, we would like to calculate the minimum and maximum of each of 1000 randomly generated normal distributions with $\mu = 1000$ and $\sigma = 10$. To do this, a placeholder data frame `x` with three columns (iteration, min and max) is created with $n = 1000$ rows for each of the random distributions to be generated. Then, we use `Sys.time()` to capture when the loop starts and end -- a common practice for optimizing code. The loop is initiated for 1 to 1000 iterations to calculate the mininum and maximum. At the end of each iteration, the min and max results are overwritten to the row that corresponds to the iteration in the placeholder `x`. 


```{r}
#Set placeholder data frame with n rows
  n <- 1000
  x <- data.frame(iteration = 1:n, 
                  min = numeric(n), 
                  max = numeric(n))

#Loop
  start <- Sys.time()
  for(i in 1:n){
    y <- rnorm(10000, 1000, 10)
    x$min[i] <- min(y)
    x$max[i] <- max(y)
  }
  Sys.time() - start

```

The above process required roughly 0.8 seconds to process. _What happens if the placeholder length were not pre-specified?_ For the given parameters, the task normally may last between 1.2 and 1.5 seconds. This may not seem to be much time, but at scale with millions if not billions of records and iterations, the time does tend to add up.

```{r}
#Set placeholder data frame without dimensions
  n <- 1000
  x <- data.frame()

#Loop
  start <- Sys.time()
  for(i in 1:n){
    set.seed(i)
    y <- rnorm(10000, 1000, 10)
    x <- rbind(x, cbind(iteration = i, 
                  min = min(y), 
                  max = max(y)))
  }
  Sys.time() - start

```


#### R-specific: `apply`

For-loops are common across all languages, but the efficiency of their implementation will vary. As was described in the previous chapter, R is an interpretted language optimized for mathematical and statistical calculation -- quite different than other languages. This means that programming in R is most optimal when vectorizing calculation -- linear algebra calculations of vectors and matrices using operations such as `+`, `-`, `*`, `%*%`, among others.

In R, the speed of for-loops may be improved using `lapply()` under certain circumstances.  `lapply()`, or _list apply_ Whereas the intermediate objects in for-loops are global variables, `lapply()` creates temporary _local variables_. 


```{r}
#Set n
  n <- 1000

#Loop
  start <- Sys.time()
  x <- lapply(1:n, function(i){
     y <- rnorm(10000, 1000, 10)
     return(cbind(iteration = i, 
                  min = min(y), 
                  max = max(y)))
  })
  x <- do.call(rbind, x)
  Sys.time() - start
```


###While
Whereas for loops require a range or list of values through which to iterate, `while()` statements keep iterating until some condition is met. The `while()` statement is formulated as follows:

```{r, eval=FALSE}
  while([condition is true]){
    
    [execute this statement]
    
  }
```

A simple case may involve drawing a random value $x$ from a normal distribution ($\mu = 1.0$, $\sigma = 0.5$) while $x$ is greater than 0.01. 
```{r, echo = FALSE}
set.seed(1)
```
```{r}
  x <- 1
  while(x > 0.01){
    x <- rnorm(1, 1, 0.5)
    print(x)
  }
  print("done!")
```


#### Exercises {-}
1. Write an if-else statement that classifies a number as positive number as "up" and a negative number as "down". Then, write a forloop to classify each record of `x` from `x_2` to `x_100` is up or down relative to the preceding record Then, use `table()` to tabular the number of up days versus down days. 

```{r}
  n <- 500
  series <- sin((1:n)/100) + cos((1:n)/80)

```

2. Fibonacci numbers are defined as $F_n = F_{n-1} + F_{n-2}$, or numbers that are defined as the sum of the preceding two numbers. For example, given an initial sequence of ```0, 1```, the next five numbers are ```1, 2, 3, 5, 8```. Using a `while()` loop, find the Fibonacci number that precedes 1,000,000.
3. Often times, data files are stored in smaller chunks to save space and enhance searchability. In some cases, data is stored in daily chunks. The National Oceanic and Atmospheric Administration (NOAA) releases data every day on environmental and atmospheric conditions, including storms. Download the data using `digIt("hail_201601", download = TRUE)` and unzip the files, then use `list.files()`, then write a loop to record the following measures in a data frame:

- month and year
- number of rows
- maximum hail size from the `maxsize` field

__Answers__

1. _If-Else Statement_.
```{r}
#define series 
  n <- 500
  series <- sin((1:n)/100) + cos((1:n)/80)
  
#write if-else for i = 2
  temp <- c()
  if(series[2] >= series[2-1]){
      temp <- c(temp, "up")
    } else{
      temp <- c(temp, "down")
    }
  
#set empty vector
  temp <- c()
  
#loop through if-statement
  for(i in 2:length(series)){
    if(series[i] >= series[i-1]){
      temp <- c(temp, "up")
    } else{
      temp <- c(temp, "down")
    }
  }
  table(temp)
```


2. _Fibonacci Sequence_.

```{r}
#define variables
  n <- 0
  n0 <- 0
  n1 <- 1
  f <- 0
  s <- c()

#enter into loop
  while(f < 1000000){
    f <- n0 + n1
    n0 <- n1
    n1 <- f
    n <- n + 1
    s <- c(s, f)
  }
  
#get result in the (n-1)th position 
  print(s[n-1])
  
```

3. _Hail files_.

```{r, eval = FALSE}
#Download the hail files to the current working directory
  library(digIt)
  digIt("hail_201601", download = TRUE)
  
#Unzip the zip file
  unzip("compressed.zip")

#Get all files that start with hail
  hail <- list.files(pattern = "^hail_\\d{6}")

#create empty dataframe
  temp <- data.frame()
  for(rec in hail){
    df <- read.csv(rec)
    maxhail <- max(df$MAXSIZE)
    date <- regmatches(rec,regexpr("\\d{6}", rec))
    rows <- nrow(df)
    temp <- rbind(temp, data.frame(max.hail = maxhail, date = date, rows = rows))
  }

  
```

## Functions
Functions are generalizable sets of code that can be used to calculate a single value, process an entire dataset, print graphs, among other things. A strong software engineering habit involves building narrowly defined functions and low-level functions that can be put together to do high-level tasks. 

A typical function is constructed as follows. The function name is assigned to an object, followed by a list of parameters that will be used as inputs into the function, followed by the script that will be executed using the input parameters. 

```{r, eval=FALSE}
  function1 <- function(parameter1, ...){
    #Script goes here
    return([output goes here])
  }
```

To execute the function, we will simply need to pass call the function and pass inputs.

```{r, eval=FALSE}
  function1(input1)
```

We can contextualize it by reconstructing a standard function such as the `mean()` method. `mean()` accepts accepts a vector `vec`, sums all values in `vec`, divides by the length of `vec`, then returns the result that is passed through `return()`. 

```{r}
#Create dataset
  n <- 1000
  df <- data.frame(id = 1:n,
                   x1 = rpois(n,3), x2 = rpois(n,10),
                   x3 = rpois(n,5), x4 = rpois(n,30),
                   x5 = rpois(n,1), x6 = rpois(n,1),
                   x7 = rpois(n,1), x8 = rpois(n,100))

#Set up Function
  meanToo <- function(vec){
    #
    # Desc:
    #   Calculate mean of a vector of numeric values
    #
    # Args:
    #   vec = vector of values
    # 
    # Return:
    #   Single mean
    #
      res <- sum(vec)/length(vec)
      return(res)
  }

#Execute 
  meanToo(df$x1)
```

But what if we wanted to obtain the mean for each row as opposed to each column? That can be achieved using the `rowMeans()` method, but we can also write a function to replicate the functionality. The function should:

- Accept the following parameters: `data` = the data frame, `start` = index value for the first column in range, `end` = index for the last column.
- steps:
    - Create an empty vector `output`
    - Loop through each row
      - Use the `mean.too()` function from above, calculate the row mean, append to `output`
    - Return `output` as result
    
```{r}
#Write function
  rowMeans2 <- function(data, start, end){
    #
    # Desc:
    #   Calculate mean for each rown
    #
    # Args:
    #   data = data frame or matrix
    #   start/end = column indices of first and last columns in data
    # 
    # Return:
    #   Vector of row means
    #
    
    output <- c()
    for(i in 1:nrow(data)){
      output <- c(output, meanToo(data[i, start:end]))
    }
    return(output)
  }

#Run function
  df$means <- rowMeans2(df, 2,9)
  head(df$means, 10)
```


## Etiquette
Notice how we rely on the `meanToo()` function that was previously built? There are some guiding principles that'll ensure that your code is clean, readable, and reusable:

1. _Plan your code_. Write or draw all the steps that are required to achieve your data processing requirements. Go through each line and cluster the steps into small, discrete modfules that can be relied upon independent of the initial context. For example, an entire data cleansing workflow should be broken into smaller functions rather than be converted into one long function. 

2. _Make your actions clear_. Write your code in a manner that can be re-usable and interpreted by other humans. The code should be self-explanatory. Annotate to make the logic and coding choices clear. For each function, include at least three descriptors so others may use your code: `Desc` for description of the function, `Args` for arguments or parameters in the code along with defaults, and `Return` indicating the output form. For example:

3. _Pretty code is readable code_. To make readable code, do:

- Indent lines: indent using two spaces to dependencies such as if-statements, loops, etc.;
- Spacing: add spaces before and after operators (e.g. `10 + 2` rather than `10+2`);
- Use `<-` instead of `=` except for when there are function calls;
- Limit each line of the code to a common page width (~140 characters).

4. _Name objects consistently_. Name new data objects and functions should follow a naming convention, such as the [Google R Guide](https://google.github.io/styleguide/Rguide.xml#identifiers).

- Variable names should be all lower case without punctuation or spaces. If a space is required, replace with a period "`.`".
- Function names should follow the style of "functionName" -- no spaces, the first letter of the second word (if any) is capitalized. Most importantly, name functions in a meaninful fashion.

As an example of these rules in action:
```{r, eval= FALSE}

#Function for calculating a mean absolute percentage error
mape <- function(actual, predicted, nas = TRUE, text = FALSE){
    #
    # Desc:
    #   Calculates mean absolute percentage error, often used for forecasting
    #
    # Args:
    #   actual = vector of original values
    #   predicted = vector of predicted values
    #   nas = logical (default = TRUE) to remove NA values
    #   text = logical (default = FALSE) to return in textual percentage form (e.g. "30%")
    # 
    # Return:
    #   A single MAPE value
    #
  
    #Calculate mape
      out <- mean(abs((predicted / actual)-1), na.rm = nas)
      
    #If statement for output options
    if(text == TRUE){
      
      #return percentage readable text 
      return(paste0(out*100, "%"))
      
    } else{
      
      #return raw
      return(out)
    }
}

#Create data frame of example data
  df <- data.frame(y = c(1,2,3,4,5),
                 yhat = c(1, 1.2, 3, 3.5, 6))

#Calculate mape for df
  mape(df$y, df$yhat)

```

#### Exercises {-}
1. Write a function that replicates the `unique()` method.
2. N-grams are a sequence of n-number of words in a sentence that are commonly relied upon for natural language processing and text analysis. Take the following sentence from the great statistician John Tukey: "Seek simplicity and distrust it." 2-grams from this sentence would include: ```"seek simplicity", "simplicity and", "and distrust", "distrust it"```. A 1-gram would be a vector of all words parsed by spaces. Write a function that can return n-grams for any sentence.

__Answers.__

1. _Replicate `unique()`_.
```{r}
uniq <- function(vec){
    #
    # Desc:
    #   Deduplicate and return unique values in a vector
    #
    # Args:
    #   vec = vector of values
    #
    # Return:
    #   A vector of unique values
    #
  
  #create empty vector
    uniq <- c()
    
  #loop through 
    for(i in vec){
      if(!(i %in% uniq)){
        uniq <- c(uniq, i)
      }
    }
  #return
    return(uniq)
}

#Try it out on a short series
  a <- rep(c(1,2,3), 10)
  uniq(a)
  
```

2. _n-grams_.
```{r}
  ngrams <- function(vec, delimiter, num.grams){
  
    #
    # Desc:
    #   Produce all unique sequential n-grams for each element in a string vector
    #
    # Args:
    #   vec = vector of string values
    #   delimiter = character that separates words
    #   num.grams = number of grams (word combinations)
    #
    # Return:
    #   A vector of n-grams
    #
    
    #split characters by 
      vec2 <- unlist(strsplit(vec, delimiter))
    
    #create placeholder then loop through each word
      grams <- c()
      for(k in num.grams:length(vec2)){
        grams <- c(grams, paste(vec2[k - 1], vec2[k]))
      }
      return(grams)
  }

  #Test it
    ngrams("Seek simplicity and distrust it.", " ", 2)
```

### What can you do with control structures?
Loops are a critical part of all parts of data science, enabling data cleaning, optimization, and automation. Loops are helpful when an function cannot be applied globally, meaning that each element, column, observation or iteration needs to be done on its own. For example, taking the sum of a random variable `x` can be done without looping as R is designed to operate with column-wise functionality. However, a moving average of 10 records would require a forloop.

#### Example: Smoothing time series of EIA Gasoline Spot Price Data {-}
What if we had a time series dataset with a fair amount of random variability and swings in volume? This sounds very much like financial and economic data -- it's often filled with noise. Let's take the [US Energy Information Administration's]() spot price data, specifically the retail [gasoline data](http://www.eia.gov/dnav/pet/xls/PET_PRI_SPT_S1_D.xls). An extract has been made available via the `digIt()` library or from the link [https://s3.amazonaws.com/whoa-data/doe_spot_prices_readme.zip](https://s3.amazonaws.com/whoa-data/doe_spot_prices_readme.zip).

```{r, warning = FALSE}
#Call rio library to open 
  library(digIt)
  df <- digIt("doe_gas_price")
```

```{r, eval = FALSE}
#Call rio library to open 
  library(rio)
  df <- import("https://s3.amazonaws.com/dspp/doe_spot_prices_readme.xls")
```


```{r, message=FALSE, warning=FALSE}
#Inspect the data
  dim(df)
  head(df,1)

#Clean and format data
  colnames(df) <- c("date","ny.values","us.gulf.values")
  df$date <- as.Date(as.character(df$date), "%Y-%m-%d")

#Plot the data using ggplot
  library(ggplot2)
  ggplot(df, aes(date,ny.values)) + geom_line()
```

 While here is a pre-built smoothing function known as `smooth()` that is optimized for this task, we will write a moving average function to illustrate control structures on the `ny.values` series.

```{r, message=FALSE, warning=FALSE, fig.height = 3}
  moving <- function(vec, lag){
    
    #
    # Desc:
    #   Produce rolling average
    #
    # Args:
    #   vec = numeric vector 
    #   lag = number of periods to add to lag
    #
    # Return:
    #   A vector of n-grams
    #
    
    new.vec <- rep(NA, lag - 1)
    
    #Loop range from *size* to number of rows in vec minus *size*
    for(i in lag:length(vec)){
      
        #Extract values of *x* from positions i-size to i
        extract <- mean(vec[(i - lag):i], na.rm = TRUE)
        
        #Calculate mean of *extract*, store to the ith value of *new*
        new.vec <- c(new.vec, extract)
    }
    return(new.vec)
  }

```

Now we can test `moving()` using a 14-day window and plot the `ny.values` versus the 14-day moving average.

```{r, message=FALSE, warning=FALSE, fig.height = 3}
#Calculate 14-day moving average
  df$new <- moving(df$ny.values, 14)

#Plot result
 ggplot(df, aes(x = date, y = ny.values)) + 
   geom_line(colour="grey") +
   geom_line(data = df, aes(x = date, y = new))

```

It's also possible to use loops within loops. What if we wanted to compare multiple window sizes, we can *nest* one loop inside another. In this case, looping through different potential window sizes helps with identifying the optimal window size.

```{r, message=FALSE, warning=FALSE}
  #Vector of windows to be tested
      windows <- c(7, 91, 182, 364)
    
    #Outer loop (index value = *size*)
    for(size in windows){
      
      #Calculate moving average by window
        df$new <- moving(df$ny.values, size)
    
      #Calculate correlation
        cor_val <- round(cor(df$new, df$ny.values, use="complete.obs"), 2)
    
      #Plot graph
      g <- ggplot(df, aes(x = date, y = ny.values)) + 
            geom_line(colour = "grey") +
            geom_line(data = df, aes(x = date, y = new), colour = "blue") + 
            ggtitle( paste("window =",size,", rho =", cor_val))
      
      #Assign new name for plot object to avoid overwriting results
        assign(paste0("g",size), g)
  }
    
  #Compare graphs. Requires gridExtra library to allow for graph juxtapositionx
    library(gridExtra)
    grid.arrange(g7, g91, g182, g364, ncol=2)
```

Note that there are some pre-canned functions that can assist with smoothing; However, coding the function from scratch will provide you with greater flexibility to tackle the task at hand.
