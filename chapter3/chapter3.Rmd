# Chapter 3: A Light Introduction to Statistical Programming

__Main question of the chapter:__  How do I get started?

__Gist:__  Bare-bone basics: Going deeper into the basics of R. Types of data and objects. Installing packages. Importing data and directories.

## Data are everywhere—and they come in all types.

- We see data everywhere, including news reports: "The Dow Jones industrial average erased earlier losses today to end 56.97 points higher at 21,865.37..."".
  - Each piece of information corresponds to a different data type (e.g., numeric, string, factors, Boolean, dates).
  - "Dow Jones industrial average" references the name of a specific stock-market index.
  - "today" references a date (as does "earlier")
  - "56.97" and "21,865.37" are numbers (with units)
  - There are also data embedded in the phrases "erased", "earlier losses" and "higher".

## Data types

In R, you encode (often implicitly) your variables/data as having one of several types of data, e.g., `numeric`, `logical`, `character`, `factor`, or `date`.

### `numeric`

As you might guess, ‘numeric' data are numbers. The numeric type is R's catch-all for all numbers, encompassing both integer and continuous numbers.

Examples of numeric data in R:
```{R, ch3 numeric}
4
4.4
4/9
pi
```

### `character`

You will most often encounter `character` data (also strings as _strings_) in datasets of linguistic text—e.g., court transcripts, novels, text messages, or government audit reports. You tell R that text is `character`-type data by wrapping the text in quotation marks, e.g., `"Text"`. Both single quotes (``) and double quotes (``) work, you just.

Text examples:
```{R, ch3 chacter}
"text"
"Text is fun!"
"Let's have an example with an interior quotation mark."
```

### `logical`

If you want to test whether something is true or false, then you've found yourself in the world of logic. Because programming and data science use logical data so frequently, they get their own data type. In R, logical data are `TRUE` or `FALSE`, which you can abbreviate as `T` or `F`. As is always the case in R: the letters' cases matter (meaning you must use `TRUE` and cannot use `true`).

Basic examples of logical data in R:
```{R, ch3 logical}
TRUE
T
FALSE
F
```

In addition to defining something as `TRUE` or `FALSE`, you can also use logical operators that test whether a statement is `TRUE` or `FALSE`. For instance,
```{R, ch3 logical operators}
# Is 3 less than 4?
3 < 4
# Is 3 greater than 4?
3 > 4
# Is 3 equal to 4?
3 == 4
```

<!-- TODO: Can we link to tables' numbers -->
The table below describe some of R's most common logical operators.

| Operator | Translation                          |
|:---------|:-------------------------------------|
| `x > y`  | `x` is greater than `y`.             |
| `x < y`  | `x` is less than `y`.                |
| `x >= y` | `x` is greater than or equal to `y`. |
| `x <= y` | `x` is less than or equal to `y`.    |
| `x == y` | `x` is equal to `y`.                 |

These logical operators are particularly common for `numeric` data, but you can actually use them for any type of data. For instance,
```{R, logical operator example}
# Is "A" equal to "a"? (Is R case sensitive?)
"A" == "a"
# Is "a" less than "A"?
"a" < "A"
# Is 3 less than "a"?
3 < "a"
# Is numeric 3 equal to character 3?
3 == "3"
```

Notice that R is indeed case sensitive: `"a"` is not the same as `"A"`, and, in fact, `"a"` precedes `"A"` in R's ordering of letters. Numbers precede letters.

Finally, it is worth noting that you can transform `TRUE` and `FALSE` to binary numeric (`1` and `0`) by multiplying them by the number `1`:
```{R, ch3 binary logical}
TRUE * 1
1 * FALSE
```

### `factor`

Factors are a bit of special data type in R, because they allow you to take one type of variable (e.g., `numeric` or `character`) and add a few more layers of information. For instance, you can add labels to your data (so that the values "Sun" and "Mon" are labeled "Sunday" and "Monday") and you also have the option to indicate that the data are order (meaning Sunday precedes Monday). You can manipulate these labels, the ordering, and a number of other factor options through the functions `factor` and `as.factor`. We will more fully explore `factor` data in the graphing section.

<!-- TODO: More on factor data in another section. Link? -->

### `date`

While there are many ways to think about dates—`character` data like "January" or `numeric` data like `1`—dates are so common (and so strange to work with) that they get their own type of data, namely, the `date` type. We will dive more into working with dates in the next chapter.

### The `class` function.

Just looking at a dataset does not always tell you the type of data. The question of type is particularly important when you read data into R from another source—you will not always know whether R read a variable as numeric, character, factor, or perhaps factor. The `class` function helps you here.

Let's see `class` is action...

```{R, ch3 class type examples}
# numeric
class(56.97)
class(57)
class(57L)
class(1/3)
# character
class("Dow Jones")
# logical
class(TRUE)
class(F)
class(3 > 2)
class(1 * TRUE)
# factor
class(factor(3))
# date
Sys.Date()
class(Sys.Date())
as.Date("2015-12-31")
class(as.Date("2015-12-31"))
# Fun
class(class)
# <Mind blows>
```

## Objects in R

Simply entering data into R's console is not going to be enough. We need a way to store the data in our computer's memory. To be able to access the data that we store, we need to give the data a name. In R parlance, we need a way to assign the values (the data) to objects stored in memory (the names).

R's assignment operator `<-` exists solely for the task of assigning a value (on the right-hand side) to the name (on the left-hand side). If you are reading code out load,^[Yes, it does happen.] `object <- value` is typically read "object gets value."

__Examples__

- `a <- 3`
- `string_ex <- "Some funny/clever words."`
- `some_logic <- TRUE`

As you can see, you get a lot of freedom in the names that you use for the objects.

Once we assign a value to an object, we can access that object's value—and perform operations on that value. For instance, we can assign a value of three to object `a`, as above, and then we can (1) check the value held in `a` by executing `a` in the console, (2) check the class of `a`, and (3) multiply `a` by 3:
```{R, ch3 assigning values}
# Assign value 3 to object named 'a'
a <- 3
# (1) Check a's value
a
# (2) Check a's class
class(a)
# (3) Multiply a by 3
a * 3
```

Looks great!

## R's object classes

### `vector`

- Vectors are one of the simplest and most used classes of objects in R.
- In R, a vector is a one-dimensional ‘list' of values. The values can be logical, numeric, factor, or character, but they must all be of the same type. If they are not, R will coerce them to the most conducive type.
- The simplest way to create a vector is with the concatenate function: `c`. For instance, to create a vector out of the numbers 1, 2, and 3, we write `c(1, 2, 3)`.
- __TODO__ Coercion example...  

### `matrix`

- R's matrices are very close what your mathematics courses taught you: they are rows and columns filled with data. You can fill your R matrices with numbers, but you can also fill them with other types of data—just as you can with vectors.
- The matrix function in R takes two arguments...
- __TODO__ Example

### The `class` function again!

__TODO__

### `data frame`

__TODO__

### `list`

### More classes

R offers many other object classes. Many of the object classes are specific to an application (e.g., geographic data like rasters or shape files) or packages (e.g., when you run a regression with the function `lm`, the function produces a special `lm` object).

## Packages

### Base R and filling the need for more functions

When you boot up R, you automatically have access to a large set of functions. You can perform mathematical operations (addition `+`, division `/`), conduct statistical summaries (`mean`, `sd`), run a regression (e.g. `lm`), plot a histogram (`hist`) and even make a map (`plot`). This original set of functions that shipped with R is called *base R* -- the basic setup when you open the box. Eventually, you will find yourself in a situation in which you need to conduct more complex and specialized tasks that are not possible by any function in base R.

Some may have the adventurous itch to program specialized functions, which may sound daunting. But fear not, there is a whole universe of functions awaiting your use on the Comprehensive R Archive Network ([CRAN](https://cran.r-project.org/)) as well as on [Github](https://github.com/). Specifically, functions are available as families of functions, formally called *packages*.

For example, imagine some crazy, hypothetical world (such as the one in which we live) where someone sends you an Excel spreadsheet that you then need to load into R. Herein lies the problem: *base R does not have a function to read directly from a spreadsheet*. But, as its name implies the `readxl` package on CRAN provides exactly the functionality you need.

### Installing packages

A large community of R users and developers contribute and maintain a (vast archive of packages)[https://cran.r-project.org/web/packages/available_packages_by_name.html]. And these package span computationally intensive tasks like reading satellite imagery to more visual tasks like creating interactive maps for websites. It is easy to tap into these vast resources, and to get started with a package like `readxl`, we only need two inputs: (A) an internet connection and (B) R's `install.packages` function.

To install `readxl`, you can install the `readxl` package by executing the following line in the R console. To break it down, `install.packages` requires the name of a known package on CRAN in the form of a string value.

```{r, eval = FALSE}
  install.packages("readxl")
```

For some packages, R will also install package dependencies -- other packages on which the request package relies. This is one of the beautiful things about R: it is an extensible language that builds on existing functionality. Entire families of packages are dependent on common functions, ensuring that a common logic is employed in making the magic happen with data.

There are sources (e.g., [METACRAN](https://www.r-pkg.org/)) that allow you to search CRAN for packages, but, as with many R-related tasks, Google and asking friends and colleagues are going to be your best bets.

### Loading packages

Like installing a new air conditioning unit, the unit is only useful when it is plugged in and turned on. R packages follow the same logic. Installing a package simply means that you now have access to the package on your machine. To take advantage of the functionality,  packages need to be loaded into R environment during each session.

To load a package, you use the `library` function in combination with the package's name. Note that whereas `install.packages` expects the package name in string format, the `library` function can accommodate both strings (e.g. "readxl") or the package as a name  (e.g. readxl) as it is now an installed resource.

```{r, eval = FALSE}
  library(readxl)
```

The `library` function will only load one package at a time, meaning that every package will need to be called individually. If we needed to load two installed packages -- `readxl` and a package for text manipulation known as `tidytext` --  we would need to do the following:

```{r, eval = FALSE}
  library(readxl)
  library(tidytext)
```

For highly complex projects requiring many packages, this will be cumbersome. We will have a fix for this shortcoming later on.

When a package is loaded, it is only temporarily help in the computer's memory. Whenever R and RStudio are closed or restarted, all loaded packages are removed from memory.  The point: you will need to load the packages again, but you do not need to install them again.

### Package management and `pacman`

While installing, loading, and updating packages in R is fairly quick and easy, the `pacman` further streamlines and simplifies these process (and many related processes).


(Maybe use this as an opportunity to install our base stack?)


There are [X] packages that greatly expand the capabilities of R. And these packages will reappear again and again throughout this book. What if we needed to load all [X] packages? The manual option is to embrace the tedium:

```{r, eval = FALSE}
  library(readxl)
  library(tidytext)
  library(dplyr)
  library(ggplot2)
  library(caret)
  ...
```

Then, when the code is shared with a collaborator, they might not have all of the packages installed, meaning the script will *crash*, requiring them to read through the error log and find all of the missing packages.

Meet: `pacman`.

Upon installing `pacman`, this simple package minimizes the mental overhead of keeping track of all packages into two lines of code:

```{r, eval = FALSE}
  library(pacman)
  p_load(readxl, tidytext, dplyr, ggplot2, caret)
```

Not only does the `p_load` function install packages, it also loads packages. Now, including this line of code at the top of each R script only requires collaborators to have `pacman` installed and the package does all of the heavy lifting of keeping packages up-to-date and in sync.

## Data I/O

- To loading data into R, you must
  - tell R where to look for the file,
  - tell R which function to use load the file, and
  - tell R the file's name.
- Directories
  - Defining directories: Special strings
  - RStudio helps you complete (tab)
- Navigating directories
  - `getwd`, `setwd`, and `dir`
  - Best practice: Define your directories to objects at the start of your script.
  - Example:
    - `main_dir <- "/Users/BlackPanther/Wakanda/NewData/"`
    - `dir(main_dir)`
    - `setwd(main_dir); getwd`
- When you want to input data in R, you want to the right function for your data's file type. - For instance, we will use the `read_csv` function (from the `readr` package) to read .csv files, whereas we will use the `read_dta` function (from the `haven` package) to read Stata .dta files.
- Assuming you know the name of the file that you want to load, we are now set!
  - Put it all together... __TODO__
  - Example... __TODO__

## Finding help

### R's help (`?` and `??`)

If you hit a snag with a function, you can access the function's help file using `?` in the console. For instance, if you want to know more about the function `read_xlsx` (from the `readxl` package), you can execute `?read_xlsx`—assuming you've already loaded the `readxl` package. If you have not already loaded the package, you can include the package's name, two colons (`::`), and the function's name, e.g., `?readxl::read_xlsx`. This little trick works in general—it is not restricted to looking up help files.

### Google and online communities

One of the best parts of R is the vibrant and (generally) helpful online community... __TODO__

## Best practices: Commenting your scripts

As you may have noticed, many of the code snippets in this chapter contained comments preceded by a hash (`#`).^[Also called a _pound sign_ or _number sign_ or _octothorpe_ in the olden days before Twitter.] The hash tells R to ignore whatever follows the hash _on the same line as the `#`_. Thus, the hash allows you to make notes (generally called comments) to yourself, your collaborators, or anyone else who may have to read through your code. These comments help you figure out what you (or your friend) were doing two years ago when you wrote the R script. For instance:
```{r, ch3 comment self, eval = F}
  # Make sure the packages are installed and loaded.
  p_load(readxl, dplyr)
  # Navigate to the data directory to load the data.
  setwd("/Users/Someone/OnlyData")
  # Load the xlsx file (named 'fake_data.xlsx')
  fake_df <- read_xlsx("fake_data.xlsx")
```
In the example above, each comment line briefly describes what we will do in the next line and why we want to do it. Often the _why_ is the most important part: with some experience, you will be able to figure out what each line of an R script does, but it is much more difficult to figure out _why_ the author wrote the 641 lines of code in the middle of a 1200-line R script.

Another popular use of comments in R—and in many other languages—is to flag questions, issues, or unfinished items. The idea here is to start the comment with a quick flag, for instance `# TODO`. This flag helps you find the unfinished parts of your document—or the parts that you want your collaborators to finish for you. For instance, we might start a document
```{R, ch3 flag ex, eval = F}
  # Make sure the packages are installed and loaded
  # FIXME: There are better packages for large datasets.
  p_load(readxl, dplyr)
  # Navigate to the data directory to load the data
  setwd("/Users/Someone/OnlyData")
  # Load the xlsx file (named 'fake_data.xlsx')
  fake_df <- read_xlsx("fake_data.xlsx")
  # TODO: Clean the dataset. Check out `stringr` and `data.table`
```

You can also use commenting (`#`) to tell R to ignore lines of code. This usage of the hash is called _commenting out_ your code, as it allows you to turn off a line of code, e.g.,
```{R, ch3 comment out, eval = F}
# Standard line of code
two_plus_two <- 2 + 2
# Commented out line of code
# two_times_two <- 2 * 2
```
In general, commenting lines of code out is most helpful for temporary changes and/or testing code. If you really do not need a code, just delete it.

Finally, it is worth saying that the style and amount of commenting, flagging, and commenting-out are highly subjective. If you find them burdensome, then you probably should cut back a bit or try a different strategy. That said, it's pretty rare for 0 comments to be an optimal number of comments in an R script.

## DIY

### Solar Generation and the NIST Net Zero Energy House

Solar energy generation has been rapidly gaining ground. In the period between 2008 and 2017, annual net generation of solar energy produced by utility scale facilities had grown by 61.3-times, from 864 thousand megawatt hours to 52,958 thousand megawatt hours.^[https://www.eia.gov/electricity/monthly/epm_table_grapher.php?t=epmt_1_01]. At the same time, solar also became more economical: photovoltaic module costs fell from \$3.37/peak watt to \$0.48/peak watt -- a 86% reduction in cost.

The increased affordability of solar among other advanced technologies opens the possibility for constructing buildings that are hyper energy efficient. For example, the Net Zero Energy Residential Test Facility is a house that produces as much energy as it uses over the course of a year. Engineered and constructed by the [National Institute of Standards and Technology (NIST)](https://pages.nist.gov/netzero), the lab home was designed to be approximately 60 percent more energy efficient than typical homes. In order to achieve net zero energy, the lab home needs to produce an energy surplus and overcome the energy consumption of a simulated family of four. In fact, within its first year, the facility produced an energy surplus that is enough to power an electric car for 1400 miles.

The test bed also generates an extraordinary amount of data that help engineers study how to make more energy efficient homes and may one day inform building standards and policies. As a first step with R, we tap into one slice of the net zero house's photovoltaic time series data, which is made available publicly at  [https://s3.amazonaws.com/nist-netzero/2015-data-files/PV-hour.csv](https://s3.amazonaws.com/nist-netzero/2015-data-files/PV-hour.csv). This data set contains hourly estimates of solar energy production and exposure on the Net Zero home's solar panels.

Suppose we wanted to know how much energy the solar arrays are exposed to in an average hour and how variable that exposure is. With only a few lines of code, we can import and summarize the information.  To start, we use `read.csv` to import a comma separated values (CSV) file stored at the location in the `url` object, which is held in the R environment as a data frame. Upon import, the CSV is held in a data frame labeled `df`. We can check the dimensions of the data frame using `dim`: The data set has n = 8,737 with 32 columns.

```{r}
#Create string object with URL
  url <- "https://s3.amazonaws.com/nist-netzero/2015-data-files/PV-hour.csv"

#Read data direct from web
  df <- read.csv(url)

#Check dimensions
  dim(df)
```

As we are primarily interested in the total amount of sunlight hitting the solar arrays at any given hour (kWh), we focus in on the variable `PV_PVInsolationHArray` in data frame `df`. To take a sneak peek of the data, we can use `head` to retrieve the first six observations.

```{r}
  head(df$PV_PVInsolationHArray)
```

To answer our questions, we can obtain a concise `summary` to gauge the hourly variability. As it turns out, the summary indicates that the photovoltaic arrays are exposed to fairly small amounts of energy for the majority of hours as indicated by the small median relative to the mean, but there are occasional periods with intense energy exposure.

```{r}
  summary(df$PV_PVInsolationHArray)
```

This can be more concisely summarized as the coefficient of variation ($CV = \frac{\text{standard deviation}}{\text{mean}}$) -- the ratio of the standard deviation and the mean. Values of the CV that exceed $CV = 1$ indicate greater dispersion. Otherwise stated, the data may be *wider than it is tall*, therefore greater vales of CV indicate there may be more noise and less consistency in the data. We compute the `mean` and standard deviation `sd`. The resulting CV indicates that one standard deviation is 1.5-times as wide as the mean, suggesting some visible degree of variability in hourly sun exposure.

```{r}
  a <- mean(df$PV_PVInsolationHArray)
  b <- sd(df$PV_PVInsolationHArray)
  print(b/a)
```

With only a few lines of code, we have shown how programming can make data analysis an efficient process. In the context of policy, programming removes the tedium of spreadsheeting, allowing an analysis to be delivered using only a few decisive keystrokes.
